{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a316bfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/randyngo/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f18cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2009 = pd.read_parquet('ss2024.parquet')\n",
    "# df2014 = pd.read_parquet('ss2024.parquet')\n",
    "# df2019 = pd.read_parquet('ss2024.parquet')\n",
    "# df2024 = pd.read_parquet('ss2024.parquet')\n",
    "df2009 = pd.read_parquet('subset2009.parquet')\n",
    "df2014 = pd.read_parquet('subset2014.parquet')\n",
    "df2019 = pd.read_parquet('subset2019.parquet')\n",
    "df2024 = pd.read_parquet('subset2024.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6ef2274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2024.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fb0ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = gpd.read_file('taxi_zones/taxi_zones.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8a9cb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zones['borough'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eec39651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boroughs = zones[['LocationID', 'borough']]\n",
    "boroughs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1940aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>Start_Lon</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>End_Lon</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2009-01-01 00:00:37</td>\n",
       "      <td>2009-01-01 00:07:31</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-73.993538</td>\n",
       "      <td>40.727442</td>\n",
       "      <td>-74.006315</td>\n",
       "      <td>40.739391</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2009-01-01 00:05:40</td>\n",
       "      <td>2009-01-01 00:10:04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-74.000174</td>\n",
       "      <td>40.730405</td>\n",
       "      <td>-73.999066</td>\n",
       "      <td>40.734198</td>\n",
       "      <td>1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2009-01-01 00:09:23</td>\n",
       "      <td>2009-01-01 00:15:32</td>\n",
       "      <td>2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-73.958610</td>\n",
       "      <td>40.784296</td>\n",
       "      <td>-73.942775</td>\n",
       "      <td>40.786082</td>\n",
       "      <td>1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2009-01-01 00:09:43</td>\n",
       "      <td>2009-01-01 00:26:57</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-73.955187</td>\n",
       "      <td>40.768987</td>\n",
       "      <td>-74.005795</td>\n",
       "      <td>40.733189</td>\n",
       "      <td>1</td>\n",
       "      <td>17.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CMT</td>\n",
       "      <td>2009-01-01 00:10:57</td>\n",
       "      <td>2009-01-01 00:32:19</td>\n",
       "      <td>4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>-73.984541</td>\n",
       "      <td>40.771447</td>\n",
       "      <td>-73.978839</td>\n",
       "      <td>40.730922</td>\n",
       "      <td>1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0      CMT  2009-01-01 00:00:37   2009-01-01 00:07:31                1   \n",
       "1      CMT  2009-01-01 00:05:40   2009-01-01 00:10:04                1   \n",
       "2      CMT  2009-01-01 00:09:23   2009-01-01 00:15:32                2   \n",
       "3      CMT  2009-01-01 00:09:43   2009-01-01 00:26:57                3   \n",
       "4      CMT  2009-01-01 00:10:57   2009-01-01 00:32:19                4   \n",
       "\n",
       "   trip_distance  Start_Lon  Start_Lat    End_Lon    End_Lat  payment_type  \\\n",
       "0            1.4 -73.993538  40.727442 -74.006315  40.739391             1   \n",
       "1            0.4 -74.000174  40.730405 -73.999066  40.734198             1   \n",
       "2            1.1 -73.958610  40.784296 -73.942775  40.786082             1   \n",
       "3            6.0 -73.955187  40.768987 -74.005795  40.733189             1   \n",
       "4            4.7 -73.984541  40.771447 -73.978839  40.730922             1   \n",
       "\n",
       "   fare_amount  extra  tip_amount  tolls_amount  hour  day_of_week  month  \\\n",
       "0          7.0    0.0        1.00           0.0     0            3      1   \n",
       "1          4.6    0.0        2.00           0.0     0            3      1   \n",
       "2          6.2    0.0        1.55           0.0     0            3      1   \n",
       "3         17.4    0.0        2.61           0.0     0            3      1   \n",
       "4         15.4    0.0        2.00           0.0     0            3      1   \n",
       "\n",
       "   year  \n",
       "0  2009  \n",
       "1  2009  \n",
       "2  2009  \n",
       "3  2009  \n",
       "4  2009  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2009.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb2a8659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new09 = pd.merge(df2009, boroughs, how='left')\n",
    "# new09 = new09.dropna()\n",
    "# new09 = new09[new09[\"payment_type\"] == 1]\n",
    "new09 = df2009.drop(['VendorID'],axis=1)\n",
    "new09 = new09.drop(['Start_Lon'],axis=1)\n",
    "new09 = new09.drop(['Start_Lat'],axis=1)\n",
    "new09 = new09.drop(['End_Lon'],axis=1)\n",
    "new09 = new09.drop(['End_Lat'],axis=1)\n",
    "\n",
    "new14 = pd.merge(df2014, boroughs, how='left', left_on='PULocationID', right_on='LocationID')\n",
    "new14 = new14.dropna()\n",
    "new14 = new14[new14[\"payment_type\"] == 1]\n",
    "\n",
    "new19 = pd.merge(df2019, boroughs, how='left', left_on='PULocationID', right_on='LocationID')\n",
    "new19 = new19.dropna()\n",
    "new19 = new19[new19[\"payment_type\"] == 1]\n",
    "\n",
    "new24 = pd.merge(df2024, boroughs, how='left', left_on='PULocationID', right_on='LocationID')\n",
    "new24 = new24.dropna()\n",
    "new24 = new24[new24[\"payment_type\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cf12d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new.head()\n",
    "# new['borough'].unique()\n",
    "# new[new['borough'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81f6a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new09.drop(['tip_amount'],axis=1)\n",
    "# onehot = pd.get_dummies(X['borough'])\n",
    "# X = X.drop(['borough'],axis=1)\n",
    "# X = X.join(onehot)\n",
    "X = X.drop(['tpep_pickup_datetime'],axis=1)\n",
    "X = X.drop(['tpep_dropoff_datetime'],axis=1)\n",
    "\n",
    "y = new09['tip_amount']\n",
    "\n",
    "X_train09, X_test09, y_train09, y_test09 = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92b9c816",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new14.drop(['tip_amount'],axis=1)\n",
    "onehot = pd.get_dummies(X['borough'])\n",
    "X = X.drop(['borough'],axis=1)\n",
    "X = X.join(onehot)\n",
    "X = X.drop(['tpep_pickup_datetime'],axis=1)\n",
    "X = X.drop(['tpep_dropoff_datetime'],axis=1)\n",
    "\n",
    "y = new14['tip_amount']\n",
    "\n",
    "X_train14, X_test14, y_train14, y_test14 = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "508c6e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new19.drop(['tip_amount'],axis=1)\n",
    "onehot = pd.get_dummies(X['borough'])\n",
    "X = X.drop(['borough'],axis=1)\n",
    "X = X.join(onehot)\n",
    "X = X.drop(['tpep_pickup_datetime'],axis=1)\n",
    "X = X.drop(['tpep_dropoff_datetime'],axis=1)\n",
    "\n",
    "y = new19['tip_amount']\n",
    "\n",
    "X_train19, X_test19, y_train19, y_test19 = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b575ce6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# X = df2024.drop(['tip_amount'],axis=1)\n",
    "X = new24.drop(['tip_amount'],axis=1)\n",
    "onehot = pd.get_dummies(X['borough'])\n",
    "X = X.drop(['borough'],axis=1)\n",
    "X = X.join(onehot)\n",
    "X = X.drop(['tpep_pickup_datetime'],axis=1)\n",
    "X = X.drop(['tpep_dropoff_datetime'],axis=1)\n",
    "\n",
    "y = new24['tip_amount']\n",
    "# y = new24['tip_amount'] / new24['fare_amount']\n",
    "\n",
    "X_train24, X_test24, y_train24, y_test24 = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1f790ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "# rf.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = rf.predict(X_test)\n",
    "\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mse)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# print(f\"Random Forest Model Performance:\")\n",
    "# print(f\"RMSE: {rmse:.2f}\")\n",
    "# print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ac72c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89e8a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# myClassifiers = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "# myClassifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99988cbe",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e0ce3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4733f31f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m21630/21630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 620us/step - loss: 127.3245 - root_mean_squared_error: 7.5752 - val_loss: 2.2589 - val_root_mean_squared_error: 1.5029\n",
      "Epoch 2/20\n",
      "\u001b[1m21630/21630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 609us/step - loss: 2.5440 - root_mean_squared_error: 1.5929 - val_loss: 2.3619 - val_root_mean_squared_error: 1.5368\n",
      "Epoch 3/20\n",
      "\u001b[1m21630/21630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 616us/step - loss: 2.4020 - root_mean_squared_error: 1.5495 - val_loss: 2.1535 - val_root_mean_squared_error: 1.4675\n",
      "Epoch 4/20\n",
      "\u001b[1m21630/21630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 598us/step - loss: 2.2930 - root_mean_squared_error: 1.5142 - val_loss: 2.1468 - val_root_mean_squared_error: 1.4652\n",
      "Epoch 5/20\n",
      "\u001b[1m21630/21630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 606us/step - loss: 2.3526 - root_mean_squared_error: 1.5332 - val_loss: 2.1553 - val_root_mean_squared_error: 1.4681\n",
      "Epoch 6/20\n",
      "\u001b[1m21630/21630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 594us/step - loss: 2.2371 - root_mean_squared_error: 1.4954 - val_loss: 2.1495 - val_root_mean_squared_error: 1.4661\n",
      "Epoch 7/20\n",
      "\u001b[1m21630/21630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 630us/step - loss: 2.4004 - root_mean_squared_error: 1.5484 - val_loss: 2.1513 - val_root_mean_squared_error: 1.4667\n",
      "Epoch 8/20\n",
      "\u001b[1m21630/21630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 693us/step - loss: 2.2587 - root_mean_squared_error: 1.5027 - val_loss: 2.1465 - val_root_mean_squared_error: 1.4651\n",
      "Epoch 9/20\n",
      "\u001b[1m21630/21630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 690us/step - loss: 2.2937 - root_mean_squared_error: 1.5143 - val_loss: 2.1427 - val_root_mean_squared_error: 1.4638\n",
      "Epoch 10/20\n",
      "\u001b[1m21630/21630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 618us/step - loss: 2.2768 - root_mean_squared_error: 1.5087 - val_loss: 2.1612 - val_root_mean_squared_error: 1.4701\n",
      "Epoch 11/20\n",
      "\u001b[1m21630/21630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 665us/step - loss: 2.2237 - root_mean_squared_error: 1.4911 - val_loss: 2.1427 - val_root_mean_squared_error: 1.4638\n",
      "Epoch 12/20\n",
      "\u001b[1m21630/21630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 641us/step - loss: 2.2784 - root_mean_squared_error: 1.5091 - val_loss: 2.1469 - val_root_mean_squared_error: 1.4652\n",
      "Epoch 13/20\n",
      "\u001b[1m21630/21630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 677us/step - loss: 2.2817 - root_mean_squared_error: 1.5101 - val_loss: 2.1450 - val_root_mean_squared_error: 1.4646\n",
      "Epoch 14/20\n",
      "\u001b[1m21630/21630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 594us/step - loss: 2.2088 - root_mean_squared_error: 1.4857 - val_loss: 2.1855 - val_root_mean_squared_error: 1.4784\n",
      "Epoch 15/20\n",
      "\u001b[1m21630/21630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 660us/step - loss: 2.3385 - root_mean_squared_error: 1.5287 - val_loss: 2.1444 - val_root_mean_squared_error: 1.4644\n",
      "Epoch 16/20\n",
      "\u001b[1m21630/21630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 510us/step - loss: 2.3095 - root_mean_squared_error: 1.5194 - val_loss: 2.1533 - val_root_mean_squared_error: 1.4674\n",
      "Epoch 17/20\n",
      "\u001b[1m21630/21630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 429us/step - loss: 2.3637 - root_mean_squared_error: 1.5372 - val_loss: 2.1423 - val_root_mean_squared_error: 1.4637\n",
      "Epoch 18/20\n",
      "\u001b[1m21630/21630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 400us/step - loss: 2.3633 - root_mean_squared_error: 1.5370 - val_loss: 2.1378 - val_root_mean_squared_error: 1.4621\n",
      "Epoch 19/20\n",
      "\u001b[1m21630/21630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 400us/step - loss: 2.2209 - root_mean_squared_error: 1.4900 - val_loss: 2.1457 - val_root_mean_squared_error: 1.4648\n",
      "Epoch 20/20\n",
      "\u001b[1m21630/21630\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 403us/step - loss: 2.3020 - root_mean_squared_error: 1.5170 - val_loss: 2.1384 - val_root_mean_squared_error: 1.4623\n",
      "\u001b[1m5341/5341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 230us/step - loss: 2.1936 - root_mean_squared_error: 1.4785\n",
      "Test RMSE: 1.4315\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)  # One output for regression\n",
    "])\n",
    "\n",
    "# model = Sequential([\n",
    "#     Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "#     Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "#     Dense(1)  # One output for regression\n",
    "# ])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['root_mean_squared_error'])  # Use MAE or RMSE for regression\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train09, y_train09, epochs=20, batch_size=64, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, rmse = model.evaluate(X_test09, y_test09)\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc10e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred09 = model.predict(X_test09)\n",
    "\n",
    "r2 = r2_score(y_test09, y_pred09)\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b977d71",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.1)\n",
    "\n",
    "# Plot loss over time\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss (MSE)')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss (MSE)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Loss Over Time')\n",
    "plt.legend()\n",
    "\n",
    "# RMSE plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['root_mean_squared_error'], label='Training RMSE')\n",
    "plt.plot(history.history['val_root_mean_squared_error'], label='Validation RMSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Model RMSE Over Time')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0e99f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)  # One output for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['root_mean_squared_error'])  # Use MAE or RMSE for regression\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train14, y_train14, epochs=20, batch_size=64, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, rmse = model.evaluate(X_test14, y_test14)\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4165fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred14 = model.predict(X_test14)\n",
    "\n",
    "r2 = r2_score(y_test14, y_pred14)\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6b8ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss over time\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss (MSE)')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss (MSE)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Loss Over Time')\n",
    "plt.legend()\n",
    "\n",
    "# RMSE plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['root_mean_squared_error'], label='Training RMSE')\n",
    "plt.plot(history.history['val_root_mean_squared_error'], label='Validation RMSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Model RMSE Over Time')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dc8cab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)  # One output for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['root_mean_squared_error'])  # Use MAE or RMSE for regression\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train19, y_train19, epochs=20, batch_size=64, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, rmse = model.evaluate(X_test19, y_test19)\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dd7961",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred19 = model.predict(X_test19)\n",
    "\n",
    "r2 = r2_score(y_test19, y_pred19)\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fde27a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss over time\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss (MSE)')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss (MSE)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Loss Over Time')\n",
    "plt.legend()\n",
    "\n",
    "# RMSE plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['root_mean_squared_error'], label='Training RMSE')\n",
    "plt.plot(history.history['val_root_mean_squared_error'], label='Validation RMSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Model RMSE Over Time')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39713d78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)  # One output for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['root_mean_squared_error'])  # Use MAE or RMSE for regression\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train24, y_train24, epochs=20, batch_size=64, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, rmse = model.evaluate(X_test24, y_test24)\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d46a236",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred24 = model.predict(X_test24)\n",
    "\n",
    "r2 = r2_score(y_test24, y_pred24)\n",
    "print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f371fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss over time\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss (MSE)')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss (MSE)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Loss Over Time')\n",
    "plt.legend()\n",
    "\n",
    "# RMSE plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['root_mean_squared_error'], label='Training RMSE')\n",
    "plt.plot(history.history['val_root_mean_squared_error'], label='Validation RMSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Model RMSE Over Time')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be3569d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafc6b87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "# # Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "# model2 = Sequential([\n",
    "#     Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dense(1)  # One output for regression\n",
    "# ])\n",
    "\n",
    "# # Compile the model\n",
    "# model2.compile(optimizer='adam', loss='mse', metrics=['mae'])  # Use MAE or RMSE for regression\n",
    "\n",
    "# # Train the model\n",
    "# model2.fit(X_train_scaled, y_train, epochs=20, batch_size=64, validation_split=0.1)\n",
    "\n",
    "# # Evaluate the model\n",
    "# loss, mae = model2.evaluate(X_test_scaled, y_test)\n",
    "# print(f\"Test MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b530f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred2 = model2.predict(X_test_scaled)\n",
    "\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# print(f\"R² Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1571ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist = pd.DataFrame(y_pred2.history)\n",
    "\n",
    "# ## Plot our history:\n",
    "# fig, ax1 = plt.subplots(2,1, figsize=(9,6))\n",
    "\n",
    "# hist[['loss', 'val_loss']].plot(ax=ax1[0])\n",
    "# hist[['accuracy', 'val_accuracy']].plot(ax=ax1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec67635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
